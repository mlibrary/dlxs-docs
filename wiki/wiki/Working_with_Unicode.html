<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	
<!-- Mirrored from localhost/wiki/Working_with_Unicode by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 03 Feb 2025 00:27:26 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
		<meta name="generator" content="MediaWiki 1.13.5" />
		<meta name="keywords" content="Working with Unicode,DLXS Wiki,Data Conversion and Preparation,Mounting a Finding Aids Collection,System Requirements" />
		<link rel="shortcut icon" href="http://localhost/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="http://localhost/mediawiki/opensearch_desc.php" title="DLXS Documentation (en)" />
		<link rel="alternate" type="application/rss+xml" title="DLXS Documentation RSS Feed" href="http://localhost/mediawiki/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="DLXS Documentation Atom Feed" href="http://localhost/mediawiki/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Working with Unicode - DLXS Documentation</title>
		<style type="text/css" media="screen, projection">/*<![CDATA[*/
			@import "../mediawiki/skins/common/sharedfa7c.css?164";
			@import "../mediawiki/skins/monobook/mainfa7c.css?164";
		/*]]>*/</style>
		<link rel="stylesheet" type="text/css" media="print" href="../mediawiki/skins/common/commonPrintfa7c.css?164" />
		<!--[if lt IE 5.5000]><style type="text/css">@import "/mediawiki/skins/monobook/IE50Fixes.css?164";</style><![endif]-->
		<!--[if IE 5.5000]><style type="text/css">@import "/mediawiki/skins/monobook/IE55Fixes.css?164";</style><![endif]-->
		<!--[if IE 6]><style type="text/css">@import "/mediawiki/skins/monobook/IE60Fixes.css?164";</style><![endif]-->
		<!--[if IE 7]><style type="text/css">@import "/mediawiki/skins/monobook/IE70Fixes.css?164";</style><![endif]-->
		<!--[if lt IE 7]><script type="text/javascript" src="/mediawiki/skins/common/IEFixes.js?164"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->
		
		<script type= "text/javascript">/*<![CDATA[*/
var skin = "monobook";
var stylepath = "/mediawiki/skins";
var wgArticlePath = "/wiki/$1";
var wgScriptPath = "/mediawiki";
var wgScript = "http://localhost/mediawiki/index.php";
var wgVariantArticlePath = false;
var wgActionPaths = [];
var wgServer = "http://localhost/";
var wgCanonicalNamespace = "";
var wgCanonicalSpecialPageName = false;
var wgNamespaceNumber = 0;
var wgPageName = "Working_with_Unicode";
var wgTitle = "Working with Unicode";
var wgAction = "view";
var wgArticleId = "16";
var wgIsArticle = true;
var wgUserName = null;
var wgUserGroups = null;
var wgUserLanguage = "en";
var wgContentLanguage = "en";
var wgBreakFrames = false;
var wgCurRevisionId = "582";
var wgVersion = "1.13.5";
var wgEnableAPI = true;
var wgEnableWriteAPI = false;
var wgRestrictionEdit = [];
var wgRestrictionMove = [];
/*]]>*/</script>
                
		<script type="text/javascript" src="../mediawiki/skins/common/wikibitsfa7c.js?164"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="../mediawiki/skins/common/ajaxfa7c.js?164"></script>
		<script type="text/javascript" src="http://localhost/mediawiki/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
		<style type="text/css">/*<![CDATA[*/
@import "http://localhost/mediawiki/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;action=raw&amp;ctype=text/css&amp;smaxage=18000";
@import "http://localhost/mediawiki/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;action=raw&amp;ctype=text/css&amp;smaxage=18000";
@import "http://localhost/mediawiki/index.php?title=-&amp;action=raw&amp;gen=css&amp;maxage=18000&amp;useskin=monobook";
/*]]>*/</style>
	</head>
<body class="mediawiki ns-0 ltr page-Working_with_Unicode">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
				<h1 class="firstHeading">Working with Unicode</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From DLXS Documentation</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<p><a href="DLXS_Wiki.html" title="DLXS Wiki">Main Page</a> &gt; <a href="Data_Conversion_and_Preparation.html" title="Data Conversion and Preparation">Data Conversion and Preparation</a> &gt; Working with Unicode
</p>
<table id="toc" class="toc" summary="Contents"><tr><td><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1"><a href="#Working_with_Unicode"><span class="tocnumber">1</span> <span class="toctext">Working with Unicode</span></a>
<ul>
<li class="toclevel-2"><a href="#About_Unicode"><span class="tocnumber">1.1</span> <span class="toctext">About Unicode</span></a></li>
<li class="toclevel-2"><a href="#Reasons_to_Use_Unicode"><span class="tocnumber">1.2</span> <span class="toctext">Reasons to Use Unicode</span></a></li>
<li class="toclevel-2"><a href="#DLXS_Background"><span class="tocnumber">1.3</span> <span class="toctext">DLXS Background</span></a></li>
<li class="toclevel-2"><a href="#Platform_Requirements"><span class="tocnumber">1.4</span> <span class="toctext">Platform Requirements</span></a></li>
<li class="toclevel-2"><a href="#DLPS_Unicode_Examples"><span class="tocnumber">1.5</span> <span class="toctext">DLPS Unicode Examples</span></a></li>
<li class="toclevel-2"><a href="#Middleware_Configuration.2C_Requirements_and_Behavior_for_Unicode"><span class="tocnumber">1.6</span> <span class="toctext">Middleware Configuration, Requirements and Behavior for Unicode</span></a>
<ul>
<li class="toclevel-3"><a href="#Configuration_and_Behavior"><span class="tocnumber">1.6.1</span> <span class="toctext">Configuration and Behavior</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1"><a href="#Data_Conversion"><span class="tocnumber">2</span> <span class="toctext">Data Conversion</span></a></li>
<li class="toclevel-1"><a href="#Indexing"><span class="tocnumber">3</span> <span class="toctext">Indexing</span></a>
<ul>
<li class="toclevel-2"><a href="#Index_Point_specification"><span class="tocnumber">3.1</span> <span class="toctext">Index Point specification</span></a></li>
<li class="toclevel-2"><a href="#Mappings_specification"><span class="tocnumber">3.2</span> <span class="toctext">Mappings specification</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Collmgr_Fields_.2F_Configuration"><span class="tocnumber">4</span> <span class="toctext">Collmgr Fields / Configuration</span></a></li>
<li class="toclevel-1"><a href="#Templates"><span class="tocnumber">5</span> <span class="toctext">Templates</span></a></li>
<li class="toclevel-1"><a href="#Unicode.2C_User_Input_and_Form_Submission"><span class="tocnumber">6</span> <span class="toctext">Unicode, User Input and Form Submission</span></a></li>
<li class="toclevel-1"><a href="#Current_Limitations_in_DLXS_Middleware"><span class="tocnumber">7</span> <span class="toctext">Current Limitations in DLXS Middleware</span></a></li>
</ul>
</td></tr></table><script type="text/javascript"> if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } </script>
<a name="Working_with_Unicode"></a><h2><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=1" title="Edit section: Working with Unicode">edit</a>]</span> <span class="mw-headline">Working with Unicode</span></h2>
<p>This document describes in some detail the issues involved in Unicode data preparation and indexing, middleware configuration, template issues and user input. In its data preparation and indexing aspect, it is mainly applicable to TextClass, BibClass and FindaidClass. With respect to the remaining issues, it relates to all the classes.
</p><p>For non-unicode specific information on data preparation for individual classes, see the following:
</p>
<ul><li> Preparing Text Class Data for Index Building / Converting Collections to Text Class
</li><li> Image Classâ€”where is this section? / Image Class Data Loading: My SQL
</li><li> Transforming Bibliographic Class Files 
</li><li> <a href="Mounting_a_Finding_Aids_Collection.html" title="Mounting a Finding Aids Collection">Mounting a Finding Aids Collection</a>: Preparing Data and Directories
</li></ul>
<a name="About_Unicode"></a><h3><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=2" title="Edit section: About Unicode">edit</a>]</span> <span class="mw-headline">About Unicode</span></h3>
<p>The authoritative source for information about Unicode is the <a href="http://www.unicode.org/" class="external text" title="http://www.unicode.org/" rel="nofollow">Unicode Consortium.</a> You will find the complete standard and lots of helpful links to other sources of information on Unicode. Even if you are familiar with Unicode, it may help to review some basic definitions:
</p><p><b>Character Repertoire</b>: a collection of abstract characters independent of how they look when printed. 
</p><p><b>Coded Character Set</b>: an assignment of a unique number to each character in a Character Repertoire. 
</p><p><b>Code Points</b>: The unique number the ISO/IEC 10646 Coded Character Set assigns to virtually every character in in all the world's alphabets. 
</p><p><b>Character Encoding Scheme</b>: Unicode is a standard built on top of ISO/IEC 10646 that, in addition to specifying the assignment of number to character, deals with things like collation, bi-directionality, normalization and, most importantly, encoding. A Character Encoding Scheme (encoding)[?] specifies how the number that stands for a character is stored in a file or in computer memory.
</p><p>There are many Character Encoding Schemes defined by the Unicode Standard but the one of interest to us is called UTF-8. The UTF-8 encoding of the Unicode Coded Character Set is the preferred encoding for Unicode on the Web. It is a multi-byte encoding, which means that it may use from 1 to 6 bytes to encode the Unicode Code Point (number) of a given character. UTF-8 and US-ASCII (0-7F hex) are identical. Above 7F, 2 or more bytes are required to encode the number assigned to a Unicode character. With Unicode it is possible for one document to contain characters from many different alphabets and to treat them uniformly for search purposes.
</p>
<a name="Reasons_to_Use_Unicode"></a><h3><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=3" title="Edit section: Reasons to Use Unicode">edit</a>]</span> <span class="mw-headline">Reasons to Use Unicode</span></h3>
<ul><li> Can represent more than one alphabet in a single document or web page
</li><li> Searchable
</li><li> Programming is simpler
</li><li> User can easily enter Latin characters via XPAT mapping functionality
</li><li> Users can enter non-ASCII characters via national keyboards, virtual keyboards, IMEs, or copy/paste
</li><li> Can be collated
</li><li> Fundamental to XML
</li><li> Better font support than for character entity references
</li></ul>
<a name="DLXS_Background"></a><h3><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=4" title="Edit section: DLXS Background">edit</a>]</span> <span class="mw-headline">DLXS Background</span></h3>
<p>Prior to release 12, DLXS depended on a variety of mechanisms to handle non-ASCII character data. These included:
</p>
<ul><li> The use of SGML character entity references (CERs) such as &Acirc; in the data. These were mapped to single character gif images to display certain characters unavailable in typical browser fonts. The problem with this mechanism was that unless the user is knowledgeable enough to type the actual 7 character sequence "&Acirc;" instead of A, for example, their search fails.
</li></ul>
<ul><li> The replacement of CERs with the corresponding ISO-8859-1 encoded character. By mapping this (typically) accented character to its unaccented ASCII equivalent, DLXS could and still can find words that contain either the accented or unaccented form of the character. This works fine but, as noted in the introduction, limits the document to a single encoding such as Latin1. In a single document one can cover German+Polish with Latin2 or German+Turkish with Latin5 but there is no single-byte encoding to properly mix German+Russian, for instance.
</li></ul>
<ul><li> Making certain uppercase letters in the user's input stand for certain characters like Thorn or Eth and "stealing" unused 8bit values to replace these CERs in the data during conversion. This was a very cumbersome process involving custom programming and involved use of mapping in XPAT indexing and searching.
</li></ul>
<p>These mechanisms are not required if the data is in Unicode especially now that Unicode fonts are widely available in the current generation of web browsers.
</p>
<a name="Platform_Requirements"></a><h3><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=5" title="Edit section: Platform Requirements">edit</a>]</span> <span class="mw-headline">Platform Requirements</span></h3>
<p>It is necessary use the latest software versions recommended in DLXS <a href="System_Requirements.html" title="System Requirements">System Requirements</a>.
There a a few terminal emulators that handle UTF-8 encoded Unicode reasonably well:
</p>
<ul><li> xterm run as
</li></ul>
<pre>     <code>xterm -u8 -fn '-misc-fixed-medium-r-semicondensed--13-120-75-75-c-60-iso10646-1'</code>
     If running under Windows you need Version 8 of Hummingbird Exceed X Server, at least.
</pre>
<ul><li> Natively, under Windows PuTTY is good. Under PuTTY Preferences-&gt;Translation select UTF-8.
</li></ul>
<p>Terminal emulators
</p>
<ul><li> Do you see ÃƒÂ© instead of Ãƒ? Or: What You See Is Not (Always) What You Have (WYSINAWYH).
</li><li> Linux
<ul><li> GNOME terminal
</li><li> <code>xterm -u8 -fn '-misc-fixed-medium-r-semicondensed--13-120-75-75-c-60-iso10646-1'</code>
</li><li>Bitstream Cyberbit and MS Arial Unicode fonts
</li></ul>
</li><li> Windows
<ul><li> <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/" class="external text" title="http://www.chiark.greenend.org.uk/~sgtatham/putty/" rel="nofollow">PuTTY</a> with Hummingbird Exceed X Server version 8 or higher on Windows
</li><li> MS Arial Unicode
</li><li> XMLSpy
</li></ul>
</li></ul>
<p><b>Tools</b>
</p><p>The goal is to get your data into UTF-8 encoded XML. You need to know how characters in your data have been encoded in order to transform to another encoding.
</p>
<ul><li> <code>iconv -c -f ISO-8859-1 -t UTF-8 -o outfile infile
</li><li> DLXSROOT/bin/t/text/ncr2utf8
</li><li> xpatutf8check
</li><li> <a href="http://hul.harvard.edu/jhove/" class="external text" title="http://hul.harvard.edu/jhove/" rel="nofollow">jhove</a> -c /l/local/jhove/conf/jhove.conf -m utf8-hul
</li><li> DLXSROOT/bin/t/text/utf8chars</code>
</li><li> OpenSP <code>osx</code>
</li><li> XMLSpy
</li></ul>
<a name="DLPS_Unicode_Examples"></a><h3><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=6" title="Edit section: DLPS Unicode Examples">edit</a>]</span> <span class="mw-headline">DLPS Unicode Examples</span></h3>
<ul><li> <a href="http://quod.lib.umich.edu/cgi/b/bib/bib-idx?c=oaister;page=simple" class="external text" title="http://quod.lib.umich.edu/cgi/b/bib/bib-idx?c=oaister;page=simple" rel="nofollow">OAIster</a> is&nbsp;%100 UTF-8 encoded XML indexed by xpatbldu and multirgn and searched using xpatu.
</li><li> Supports Latin, Greek, Cyrillic, Han, Hiragana, Katakana and Hangul characters.
</li><li> Highlighting based on .dd file character mappings.
</li><li> <a href="http://www.dlxs.org/training/workshop200607/unicode/oaisterdatadict.html" class="external text" title="http://www.dlxs.org/training/workshop200607/unicode/oaisterdatadict.html" rel="nofollow">OAIster data dictionary</a>
</li></ul>
<ul><li> <a href="http://quod.lib.umich.edu/cgi/t/text/text-idx?c=sampletc_utf8;page=simple" class="external text" title="http://quod.lib.umich.edu/cgi/t/text/text-idx?c=sampletc_utf8;page=simple" rel="nofollow">Workshop example</a> is&nbsp;%100 UTF-8 encoded XML containing English, French and Greek and indexed by xpatbldu and xmlrgn and searched using xpatu. Wordwheel?
</li></ul>
<a name="Middleware_Configuration.2C_Requirements_and_Behavior_for_Unicode"></a><h3><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=7" title="Edit section: Middleware Configuration, Requirements and Behavior for Unicode">edit</a>]</span> <span class="mw-headline">Middleware Configuration, Requirements and Behavior for Unicode</span></h3>
<p>XPAT version 5.3.2
</p>
<pre>   * 5.3 XPAT can read 5.2 indexes, i.e. 5.3 is backward compatible
   * 5.2 XPAT <b>cannot</b> read 5.3 indexes
</pre>
<p>Perl 5.8.3 or higher is required. 5.8.8 is better. Avoid 5.8.6 (debugger problem).
</p>
<a name="Configuration_and_Behavior"></a><h4><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=8" title="Edit section: Configuration and Behavior">edit</a>]</span> <span class="mw-headline">Configuration and Behavior</span></h4>
<p>To make legacy Latin-1 encoded SGML data work:
</p>
<ul><li> The collection manager (collmgr) <code>locale</code> field should be set to <code>en_US</code> to use <code>xpat</code> instead of <code>xpatu</code> to read the index.
</li><li> If there are character entity references like "&eacute;", declare them in the DLXSROOT/web/(c)/(collection)/entitiesdoctype.chnk file (copied from DLXSROOT/misc/sgml), if not already present in that file.
</li></ul>
<p>The basic assumption is that <b>ANY</b> input (user typed or search results form XPAT) is utf-8 encoded XML. Why? How? From what encoding?
</p>
<ul><li> user input that is not valid UTF-8 will be transcoded into UTF-8 and reserved characters are turned into character entity references like &amp;. Why? What effect on searching for tags? debug=qmap
</li><li> search results from XPAT are are processed through the DlpsUtils::Sgml2XmlFilter to transcode into UTF-8 and to change SGML-style singletons (e.g. &lt;LB&gt;) to XML-style singletons (e.g. &lt;LB/&gt;).
</li></ul>
<p>Downside: Searches for accented characters will fail in Latin-1 collections because the user's search term will be converted to UTF-8 but the collection data will be Latin-1. Unaccented searches will still work.
</p><p>All XML templates have <code>&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;</code> elements to ensure user input is UTF-8 and to tell the browser to use UTF-8 encoding when rendering the page content.
</p><p><br />
</p>
<a name="Data_Conversion"></a><h2><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=9" title="Edit section: Data Conversion">edit</a>]</span> <span class="mw-headline">Data Conversion</span></h2>
<p>If your data does not come to you in Unicode UTF-8 encoded XML, conversion is necessary. A typical conversion might be as follows. Note that you may only need to perform just one of (A) or (B) depending on what form your data takes. That is, non-ASCII characters in your data may be represented by entities or encoded directly in, for instance, ISO-8859-1. It is possible that both steps (A) and (B) may be required.
</p><p>A useful reference to Unicode characters is the file <code>UnicodeData.txt</code> available from the Unicode Consortium and delivered with Perl 5.8 under, for example, <code>PERLROOT/perl/lib/5.8.3/unicore/</code>.
</p><p>(A) Convert the data to the Unicode UTF-8 encoding
Use the iconv program. The following example on Linux assumes your data is initially encoded in ISO-8859-1/Latin1:
</p>
<pre>   <code>iconv -c -f ISO-8859-1 -t UTF-8 -o outfile infile</code>
</pre>
<p>Use the Perl Unicode.pm module in a script like the following:
</p><p><code>
</p>
<pre>   #!/l/local/bin/perl -w
   use strict;
   use Unicode::MapUTF8 qw(to_utf8);
   while( &lt;&gt; ) {
   print to_utf8({ -string =&gt; $_, -charset =&gt; 'ISO-8859-1' }); }
</pre>
<p></code>
</p><p>Use a program like XMLSpy to read in your file and write it out UTF-8 encoded.
(B) Convert numeric character references (NCRs) and SGML character entity references (CERs) to Unicode UTF-8 encoded characters
</p><p>Since your ultimate goal is to have UTF-8 encoded XML encoded recall that XML has 5 predefined CERs which you do not need to convert and which the utilities described below do not touch. They are &amp;, &lt;, &gt;, &amp;apos; and &quot;.
</p><p>Programs such as XMLSpy or osx may do the needed conversions for you but vary in their handling of SGML SDATA and NDATA entities. In some cases you may benefit from use of the following two utilities in addition..
</p><p>For NCRs, i.e. references of the form &amp;#DDDD; where D is a decimal digit or &amp;#xXXXX; where X is a hexadecimal digit, you can use the DLXS utility program <code>DLXSROOT/bin/t/text/ncr2utf8</code> run as:
</p><p><code>
</p>
<pre>   ncr2utf8 inputfile &gt; outputfile
</pre>
<p></code>
</p><p>For CERs, e.g. references like &Aring;, you may need to analyze the references present in your data. The program <code>DLXSROOT/bin/t/text/findEntities.pl</code> will generate a list of CERs in your data.
</p><p>It is likely that most or even all CERs in your data will come from one of the ISO Character Entity Sets: ISOamsa, ISOamsb, ISOamsc, ISOamsn, ISOamso, ISOamsr, ISOcyr1, ISOcyr2, ISOgrk1, ISOgrk2, ISOgrk3, ISOgrk4, ISOlat1, ISOlat2, ISOmfrk, ISOnum, ISOpub, ISOtech, MMLalias or MMLextra. You can use <code>DLXSROOT/bin/t/text/isocer2utf8</code> run as:
<code>
</p>
<pre>   isocer2utf8 inputfile &gt; outputfile
</pre>
<p></code>
</p><p>to translate these CERs directly to UTF-8. Running <code>findEntities.pl</code> after this will identify any CERs outside these ISO sets.
</p><p>Another option is to use an SGML parser like onsgmls together with Character Entity Declarations that substitute the Unicode NCR for the CER in the parsed output followed by a run of ncr2utf8 to complete the conversion.
</p><p>Note that If you started with SGML, you may need to touch up the SGML to make it (and its DTD) XML compliant if you rely solely on the small utility programs supplied with the DLXS release. This process is outside the scope of this document (but see <code>DLXSROOT/misc/sgml/textclass.stripped.xml.dtd</code> for an example of the XML version of textclass.dtd). At this point you should have UTF-8 encoded XML data ready to index.
</p>
<a name="Indexing"></a><h2><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=10" title="Edit section: Indexing">edit</a>]</span> <span class="mw-headline">Indexing</span></h2>
<p>Refer to files in <code>DLXSROOT/prep/s/sampletc_utf8</code> and <code>DLXSROOT/bin/s/sampletc_utf8</code> for the following discussion.
</p><p>DLXS delivers a Makefile to take you through the process of building the main XPAT index and the fabricated region indexes. The process is very similar for Latin1 encoded SGML data and UTF-8 encoded XML data. This process is outlined in TextClass Indexing. (LINK) The main difference between the non-Unicode Makefile and the Unicode Makefile is that xpatbldu, xpatu and xmlrgn are used instead of xpatbld, xpat and sgmlrgn.
</p><p>Be sure your XML data file begins with the XML declaration:
<code>
</p>
<pre>   &lt;?xml version="1.0" encoding="UTF-8"?&gt;
</pre>
<p></code>
Without this declaration, xmlrgn will not build correct region indexes.
</p><p>The most important input to the indexing process is the XPAT Data Dictionary (LINK). If your data spans several languages, especially those languages with non-Latin alphabets, you will need to configure a Data Dictionary that takes this into account. The <code>sampletc_utf8.blank.dd</code> can be used as a starting point and with some editing is sufficient for Latin based languages. There are two sections in the Data Dictionary that need attention: the Index Points and the Mappings.
</p><p>Once these sections in the Data Dictionary have been configured the indexing process can proceed via the Makefile. Note that if you have XML element or attribute names that contain non-ASCII characters in your document you should use multirgn to generate the region indexes due to a limitation in xmlrgn. It is expected that this case is rare.
</p>
<a name="Index_Point_specification"></a><h3><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=11" title="Edit section: Index Point specification">edit</a>]</span> <span class="mw-headline">Index Point specification</span></h3>
<p>This specification tells XPAT what points in the data to index. Typically, XPAT is directed to index and search beginning at an alphabetic character following a blank space, i.e. a word. Here is the Index Point specification section of the <code>sampletc_utf8.blank.dd</code> in prep:
<code>
</p>
<pre>  &lt;IndexPoints&gt;
       &lt;IndexPt&gt; &amp;printable.&lt;/IndexPt&gt;
       &lt;IndexPt&gt;&amp;printable.-&lt;/IndexPt&gt;
       &lt;IndexPt&gt;-&amp;printable.&lt;/IndexPt&gt;
       &lt;IndexPt&gt;&amp;printable.&amp;lt.&lt;/IndexPt&gt;
       &lt;IndexPt&gt;&amp;printable.&amp;amp.&lt;/IndexPt&gt;
       &lt;IndexPt&gt; &amp;Latin.&lt;/IndexPt&gt;
       &lt;IndexPt&gt;&amp;Latin.-&lt;/IndexPt&gt;
       &lt;IndexPt&gt;-&amp;Latin.&lt;/IndexPt&gt;
       &lt;IndexPt&gt;&amp;Latin.&amp;lt.&lt;/IndexPt&gt;
       &lt;IndexPt&gt;&amp;Latin.&amp;amp.&lt;/IndexPt&gt;
       &lt;IndexPt&gt; &amp;Greek.&lt;/IndexPt&gt;
       &lt;IndexPt&gt;&amp;Greek.-&lt;/IndexPt&gt;
       &lt;IndexPt&gt;-&amp;Greek.&lt;/IndexPt&gt;
       &lt;IndexPt&gt;&amp;Greek.&amp;lt.&lt;/IndexPt&gt;
       &lt;IndexPt&gt;&amp;Greek.&amp;amp.&lt;/IndexPt&gt;
     &lt;/IndexPoints&gt;
</pre>
<p></code>
</p><p>The <code>sampletc_utf8.xml</code> data file contains characters from the Latin and Greek alphabets. Index points are defined for the characters from each of those alphabets using XPAT Unicode metacharacters like "&amp;Latin." and "&amp;Greek.". These metacharacters group Unicode characters into "blocks" which correspond roughly to alphabets. The document The XPAT Data Dictionary has a list of these Unicode metacharacters together with the characters that belong to each block (about midway through the section). If your character data is Latin-based it will probably suffice to simply remove the Greek elements from <code>sampletc_utf8.blank.dd</code>.
</p><p>It is not advisable to create a Data Dictionary that specifies all the blocks so as to create s "universal" Data Dictionary. This would impose a performance and memory penalty on XPAT at runtime.
</p><p>Not all languages have a concept of upper and lower case.
</p><p>Languages such as Chinese do not separate "words" with spaces. This presents a problem for XPAT. A partial solution is to specify every character to be an index point:
</p><p><code>&lt;IndexPt&gt;&amp;Hangul.&amp;Hangul.&lt;/IndexPt&gt;</code>
</p><p>This would result in an index 4 times the size of the data and a large runtime memory requirement for the XPAT index point table and as of this writing should be considered experimental. There is a probability of false hits but that should decrease as the length of the query increases.
</p>
<a name="Mappings_specification"></a><h3><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=12" title="Edit section: Mappings specification">edit</a>]</span> <span class="mw-headline">Mappings specification</span></h3>
<p>Case insensitivity makes it easier for users to enter query terms. This is implemented in the Mappings section by mapping uppercase characters to their lowercase equivalent. Keyboards in the United States usually do not have keys for the accented characters used in European languages. These accented characters are mapped to their unaccented forms in the Mappings section. This allows search and retrieval whether the character appears accented or unaccented in the data. Apropos of Unicode, here is a part of the Mappings section devoted to mapping uppercase Greek to lowercase:
<code>
</p>
<pre>       ...
       &lt;Map&gt;&lt;From&gt;U+0391&lt;/From&gt;&lt;To&gt;U+03B1&lt;/To&gt;&lt;/Map&gt;
       &lt;Map&gt;&lt;From&gt;U+0392&lt;/From&gt;&lt;To&gt;U+03B2&lt;/To&gt;&lt;/Map&gt;
       &lt;Map&gt;&lt;From&gt;U+0393&lt;/From&gt;&lt;To&gt;U+03B3&lt;/To&gt;&lt;/Map&gt;
       &lt;Map&gt;&lt;From&gt;U+0394&lt;/From&gt;&lt;To&gt;U+03B4&lt;/To&gt;&lt;/Map&gt;
       &lt;Map&gt;&lt;From&gt;U+0395&lt;/From&gt;&lt;To&gt;U+03B5&lt;/To&gt;&lt;/Map&gt;
       ...
</pre>
<p></code>     
Note that the Greek characters are specified using the "U+" Unicode notation. The number following the "U+" is the Unicode Code Point for the character expressed in hexadecimal notation. From this one can see that the Data Dictionary can be built entirely form ASCII characters. It is not necessary to have a UTF-8 enabled editor. The XPAT Unicode implementation currently accepts values up to U+FFFF (65535). This covers all the characters defined in Unicode Plane 0 also referred to as the Basic Multilingual Plane.
</p><p>While there are characters in higher planes they are relatively rare and this XPAT limitation is not expected to present an obstacle to indexing your Unicode-based texts. Should the need arise XPAT can be extended to use a full 32 bit word internally. As there is little need for this currently it is more memory efficient to use a 16 bit word to store characters in memory.
</p><p>You will need to analyze your texts to decide what sort of mapping may be useful to your target audiences. There are many issues to consider. Input mechanisms dominate these considerations.
</p>
<ul><li> Do your your users have Western European keyboards? It is not necessary to map accented to unaccented characters, though it is harmless to do so for users that do not have such keyboards. The accented characters are indexed and accepted as input and can be retrieved from the text.
</li><li> Do your target users have Input Method Editors readily available and know how to use them to enter non-Latin characters?
</li><li> Do your users have antiquated browsers with poor font support for Unicode?
</li></ul>
<p>DLXS is exploring the addition of a configurable javascript popup virtual keyboard to allow users to enter characters from alphabets for which they lack a physical keyboard.
</p>
<a name="Collmgr_Fields_.2F_Configuration"></a><h2><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=13" title="Edit section: Collmgr Fields / Configuration">edit</a>]</span> <span class="mw-headline">Collmgr Fields / Configuration</span></h2>
<p>To put your data online you will naturally need to define a collection in the collection database using Collmgr. There are two differences between a non-Unicode collection and a Unicode collection. As of Release 12, the Wordwheel is based solely on Unicode so it is not possible to have a Wordwheel for a non-Unicode collection. Leave the wwappmodule, wwdd fields blank.
To configure a Unicode collection set the locale field to a UTF-8 locale value such as en_US.UTF-8. You can get a list of locale values recognized by your Unix system by typing locale -a at the shell prompt. A UTF-8 locale setting affects several areas of functionality in the middleware.
</p>
<ul><li> The middleware will use xpatu search engine to search the collection data. This implies that the data was indexed by xpatbldu and xmlrgn/multirgn. This does not apply to ImageClass which is migrating to MySQL searching. DLXS release 11 was the first release offering xpatu and xpatbldu.
</li><li> The middleware will expect user input to be UTF-8 encoded. More on this below.
</li><li> The middleware will send to charset=UTF-8 to the browser when outputting processed HTML templates. This will cause the browser to interpret the output from the middleware as UTF-8 and select a Unicode font for display purposes. Browsers lacking a Unicode font will display characters in a garbled manner that includes the hollow rectangular box for some characters.
</li><li> Perl's internal UTF-8 flag is set on string data in the middleware to handle multi-byte characters.
</li></ul>
<a name="Templates"></a><h2><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=14" title="Edit section: Templates">edit</a>]</span> <span class="mw-headline">Templates</span></h2>
<p>As of Release 12, with the exception of BibClass, all XML templates templates are transformed into HTML having a <code>&lt;META&gt;</code> tag with charset=utf-8. BibClass continues to use HTML templates. To allow the XML templates to continue to work for data from non-Unicode collections while at the same time supporting Unicode data the non-Unicode data is converted at output-time from iso-8859-1 to UTF-8 encoding. In the case of BibClass, the META tag charset value is processed on output to be set to either UTF-8 or iso-8859-1 depending on the encoding of the collection.
</p>
<a name="Unicode.2C_User_Input_and_Form_Submission"></a><h2><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=15" title="Edit section: Unicode, User Input and Form Submission">edit</a>]</span> <span class="mw-headline">Unicode, User Input and Form Submission</span></h2>
<p>The encoding of user input to HTML forms is a complex area not made any easier by browser bugs and standards that do not address the problem fully. The best discussion of this topic is by A.J.Flavell. Basically the problem is that there is no reliable way for the browser to convey to the middleware what encoding is in effect for the data entered into a form by the user. Quoting Mr. Flavell:
</p>
<dl><dd>"In practice, browsers normally display the contents of text fields according to the character coding (charset) that applies for the HTML page as a whole; and when it submits the text fields they are effectively in this same coding. Thus if the server sent out the (page containing the) form with a definite charset specification, it could normally assume that the submitted data can be interpreted in accordance with the same charset. There are however anomalies of various kinds, some of which have been seen and understood by the author of this note, some of which have been seen and not understood, and some of which are only anecdotal at the moment.
</dd></dl>
<dl><dd>In addition to these considerations, some users may be typing-in or pasting-in text from an application that uses their local character coding (practical examples being macRoman on a Mac; or MS-DOS CP850 being copied out of a DOS window on an MS Windows PC), into a text field of a document that used the author's - different - character coding (let's say for the simplest example, iso-8859-1): the user might then submit the form, disregarding that what they are seeing in the text area is not what they intended to send. [...] 
</dd></dl>
<dl><dd>Given this state of affairs we can see that user data entry is not 100% reliable. Nonetheless, it is reasonable to assume the following in a page send by the middleware with charset=UTF-8:"
</dd></dl>
<ul><li> Users typing at a plain old US keyboard are generating ASCII codes which are by default UTF-8. So If a text contains a mixture of non-Latin or accented Latin characters and character data from the ASCII character set (UTF-8 single-byte-encoded Unicode characters) it has the potential to be searched effectively from an ASCII keyboard.
</li><li> Users copying from DLXS results in their browser window and pasting back into a DLXS search form are generating the UTF-8 encoded data expected by the middleware.
</li><li> Users typing input via an Input Method Editor (IME) will generate UTF-8 data as expected by the middleware.
</li><li> Users entering search strings via a javascript virtual keyboard will generate UTF-8 encoded data.
</li><li> Users typing from national keyboards may enter UTF-8 if their system is properly configured.
</li></ul>
<p>Beyond these assertions it is impossible to generalize about how copying and pasting characters from arbitrary sources into an input field might be expected to behave.
</p>
<a name="Current_Limitations_in_DLXS_Middleware"></a><h2><span class="editsection">[<a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit&amp;section=16" title="Edit section: Current Limitations in DLXS Middleware">edit</a>]</span> <span class="mw-headline">Current Limitations in DLXS Middleware</span></h2>
<p>The middleware supports collections with different character encodings in single collection mode and in cross-collection mode. However the encodings are limited to Unicode UTF-8 and ISO8859-1 (Latin1).
Any user input that is not valid UTF-8 is assumed to be Latin1 encoded. This input is transcoded to UTF-8 under this assumption. Because ASCII is, by default, UTF-8, input is not changed and XPAT Latin1-based collection queries will proceed successfully if the data dictionary maps accented character to their unaccented base character. A Latin1 XPAT search result is converted to UTF-8 to enable the data to pass through the XML/XSLT parsers on output and to display correctly in the web template which is set to charset=UTF-8. This creates a minor deficiency if the user copies a string of accented characters from the results back into the search form. The characters are now UTF-8 encoded and will not be found in a Latin1 encoded collection.
</p><p><br />
<a href="#top" title="">Top</a>
</p>
<!-- 
NewPP limit report
Preprocessor node count: 48/1000000
Post-expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Expensive parser function count: 0/100
-->

<!-- Saved in parser cache with key mediawiki_dlxsdocs_15:pcache:idhash:16-0!1!0!!en!2 and timestamp 20250202211350 -->
<div class="printfooter">
Retrieved from "<a href="Working_with_Unicode.html">http://localhost/wiki/Working_with_Unicode</a>"</div>
						<!-- end content -->
			<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="Working_with_Unicode.html" title="View the content page [c]" accesskey="c">Page</a></li>
				 <li id="ca-talk" class="new"><a href="http://localhost/mediawiki/index.php?title=Talk:Working_with_Unicode&amp;action=edit" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=edit" title="You can edit this page.&#10;Please use the preview button before saving. [e]" accesskey="e">Edit</a></li>
				 <li id="ca-history"><a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;action=history" title="Past versions of this page. [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="http://localhost/mediawiki/index.php?title=Special:UserLogin&amp;returnto=Working_with_Unicode" title="You are encouraged to log in, it is not mandatory however. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(../dlxs15/uploads/DLXS_logo2.gif);" href="Main_Page.html" title="Visit the Main Page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="Main_Page.html">Main Page</a></li>
				<li id="n-portal"><a href="DLXS_Documentation_Community_Portal.html" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-currentevents"><a href="DLXS_Documentation_Current_events.html" title="Find background information on current events">Current events</a></li>
				<li id="n-recentchanges"><a href="Special_RecentChanges.html" title="The list of recent changes in the wiki. [r]" accesskey="r">Recent changes</a></li>
				<li id="n-randompage"><a href="Mounting_a_Bib_Class_Collection.html" title="Load a random page [x]" accesskey="x">Random page</a></li>
				<li id="n-help"><a href="Help_Contents.html" title="The place to find out.">Help</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="http://localhost/wiki/Special:Search" id="searchform"><div>
				<input id="searchInput" name="search" type="text" title="Search DLXS Documentation [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search the pages for this text" />
			</div></form>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="Special_WhatLinksHere/Working_with_Unicode.html" title="List of all wiki pages that link here [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="Special_RecentChangesLinked/Working_with_Unicode.html" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-specialpages"><a href="Special_SpecialPages.html" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="http://localhost/mediawiki/index.php?title=Working_with_Unicode&amp;oldid=582" title="Permanent link to this version of the page">Permanent link</a></li>			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="../mediawiki/skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
			<ul id="f-list">
				<li id="lastmod"> This page was last modified on 13 August 2007, at 20:06.</li>
				<li id="viewcount">This page has been accessed 3,884 times.</li>
				<li id="privacy"><a href="DLXS_Documentation_Privacy_policy.html" title="DLXS Documentation:Privacy policy">Privacy policy</a></li>
				<li id="about"><a href="DLXS_Documentation_About.html" title="DLXS Documentation:About">About DLXS Documentation</a></li>
				<li id="disclaimer"><a href="DLXS_Documentation_General_disclaimer.html" title="DLXS Documentation:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served in 0.118 secs. --></body>
<!-- Mirrored from localhost/wiki/Working_with_Unicode by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 03 Feb 2025 00:27:28 GMT -->
</html>
